#Smart City Data Engineering Project

This project is focused on building a scalable data engineering pipeline for a Smart City application. The system ingests real-time data from various sources such as vehicles, GPS systems, weather sensors, and public services, processes it using big data technologies, and stores it for analytical purposes. The pipeline ensures efficient handling of large-scale, real-time data for urban planning and decision-making.

##Key Features:
Data Ingestion: Real-time data streaming using Apache Kafka.
Data Processing: Distributed processing using Apache Spark for real-time transformations and analysis.
Data Storage: Scalable storage on AWS S3 for both raw and processed data.
ETL Pipeline: Automated metadata cataloging and ETL operations with AWS Glue.
Data Warehousing: Structured data storage and querying using Amazon Redshift and Amazon Athena.
Data Visualization: Interactive dashboards and reporting via Power BI and Tableau for decision support.
Containerization: Deployed using Docker for easy scalability and portability.
##Technologies Used:
Apache Kafka (Data streaming)
Apache Spark (Distributed data processing)
AWS S3, Glue, Redshift, Athena (Cloud storage, ETL, and querying)
Docker (Containerization)
Power BI, Tableau (Data visualization)
This system is designed to improve urban resource management, traffic control, and emergency services through real-time insights derived from smart city data.
